---
# Source: oryx-gateway/charts/apicurio-registry/templates/sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: oryx-apicurio-registry
  labels:
    helm.sh/chart: "apicurio-registry-3.8.0"
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: oryx
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flink-operator
  namespace: components
  labels:
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: "1.8.0"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: flink-kubernetes-operator-1.8.0
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flink
  namespace: components
  labels:
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: "1.8.0"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: flink-kubernetes-operator-1.8.0
  annotations:
    helm.sh/resource-policy: keep
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/010-ServiceAccount-strimzi-cluster-operator.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: strimzi-cluster-operator
  namespace: components
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: service-account
    release: oryx
    heritage: Helm
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/webhook.yaml
apiVersion: v1
kind: Secret
metadata:
  name: flink-operator-webhook-secret
  namespace: components
type: Opaque
data:
  password: cGFzc3dvcmQxMjM0
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/flink-operator.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flink-operator-config
  namespace: components
  labels:
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: "1.8.0"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: flink-kubernetes-operator-1.8.0
data:
  flink-conf.yaml: |+
    ################################################################################
    #  Licensed to the Apache Software Foundation (ASF) under one
    #  or more contributor license agreements.  See the NOTICE file
    #  distributed with this work for additional information
    #  regarding copyright ownership.  The ASF licenses this file
    #  to you under the Apache License, Version 2.0 (the
    #  "License"); you may not use this file except in compliance
    #  with the License.  You may obtain a copy of the License at
    #
    #      http://www.apache.org/licenses/LICENSE-2.0
    #
    #  Unless required by applicable law or agreed to in writing, software
    #  distributed under the License is distributed on an "AS IS" BASIS,
    #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    #  See the License for the specific language governing permissions and
    # limitations under the License.
    ################################################################################
    
    # Flink job/cluster related configs
    taskmanager.numberOfTaskSlots: 1
    parallelism.default: 1
    
    # Flink operator related configs
    # kubernetes.operator.reconcile.interval: 60 s
    # kubernetes.operator.reconcile.parallelism: 5
    # kubernetes.operator.flink.client.cancel.timeout: 1 min
    # kubernetes.operator.resource.cleanup.timeout: 60 s
    # kubernetes.operator.observer.rest-ready.delay: 10 s
    # kubernetes.operator.observer.progress-check.interval: 10 s
    # kubernetes.operator.observer.savepoint.trigger.grace-period: 10 s
    # kubernetes.operator.flink.client.timeout: 10 s
    # kubernetes.operator.deployment.rollback.enabled: false
    # kubernetes.operator.deployment.readiness.timeout: 5min
    # kubernetes.operator.user.artifacts.base.dir: /opt/flink/artifacts
    # kubernetes.operator.job.upgrade.ignore-pending-savepoint: false
    # kubernetes.operator.watched.namespaces: ns1,ns2
    # kubernetes.operator.label.selector: flink=enabled
    # kubernetes.operator.dynamic.namespaces.enabled: false
    # kubernetes.operator.retry.initial.interval: 5 s
    # kubernetes.operator.retry.interval.multiplier: 2
    # kubernetes.operator.retry.max.attempts: 10
    # kubernetes.operator.exception.stacktrace.enabled: false
    # kubernetes.operator.exception.stacktrace.max.length: 2048
    # kubernetes.operator.exception.field.max.length: 2048
    # kubernetes.operator.exception.throwable.list.max.count: 2
    # kubernetes.operator.exception.label.mapper: Job has already been submitted:duplicatedJobFound,Server returned HTTP response code:httpResponseCodeFound
    # kubernetes.operator.leader-election.enabled: false
    # kubernetes.operator.leader-election.lease-name: flink-operator-lease
    
    # kubernetes.operator.metrics.reporter.slf4j.factory.class: org.apache.flink.metrics.slf4j.Slf4jReporterFactory
    # kubernetes.operator.metrics.reporter.slf4j.interval: 5 MINUTE
    
    # Flink Config Overrides
    kubernetes.operator.metrics.reporter.slf4j.factory.class: org.apache.flink.metrics.slf4j.Slf4jReporterFactory
    kubernetes.operator.metrics.reporter.slf4j.interval: 5 MINUTE
    
    kubernetes.operator.reconcile.interval: 15 s
    kubernetes.operator.observer.progress-check.interval: 5 s
    
    kubernetes.operator.health.probe.enabled: true
    kubernetes.operator.health.probe.port: 8085
  log4j-operator.properties: |+
    ################################################################################
    #  Licensed to the Apache Software Foundation (ASF) under one
    #  or more contributor license agreements.  See the NOTICE file
    #  distributed with this work for additional information
    #  regarding copyright ownership.  The ASF licenses this file
    #  to you under the Apache License, Version 2.0 (the
    #  "License"); you may not use this file except in compliance
    #  with the License.  You may obtain a copy of the License at
    #
    #      http://www.apache.org/licenses/LICENSE-2.0
    #
    #  Unless required by applicable law or agreed to in writing, software
    #  distributed under the License is distributed on an "AS IS" BASIS,
    #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    #  See the License for the specific language governing permissions and
    # limitations under the License.
    ################################################################################
    
    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender
    
    # Log all infos to the console
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %style{%d}{yellow} %style{%-30c{1.}}{cyan} %highlight{[%-5level]%notEmpty{[%X{resource.namespace}/}%notEmpty{%X{resource.name}]} %msg%n%throwable}
    
    # Do not log config loading
    logger.conf.name = org.apache.flink.configuration.GlobalConfiguration
    logger.conf.level = WARN
    
    # Avoid logging fallback key INFO messages
    logger.conf.name = org.apache.flink.configuration.Configuration
    logger.conf.level = WARN
    
    # Flink Operator Logging Overrides
    # rootLogger.level = DEBUG
    # logger.operator.name= org.apache.flink.kubernetes.operator
    # logger.operator.level = DEBUG
    
  log4j-console.properties: |+
    ################################################################################
    #  Licensed to the Apache Software Foundation (ASF) under one
    #  or more contributor license agreements.  See the NOTICE file
    #  distributed with this work for additional information
    #  regarding copyright ownership.  The ASF licenses this file
    #  to you under the Apache License, Version 2.0 (the
    #  "License"); you may not use this file except in compliance
    #  with the License.  You may obtain a copy of the License at
    #
    #      http://www.apache.org/licenses/LICENSE-2.0
    #
    #  Unless required by applicable law or agreed to in writing, software
    #  distributed under the License is distributed on an "AS IS" BASIS,
    #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    #  See the License for the specific language governing permissions and
    # limitations under the License.
    ################################################################################
    
    # This affects logging for both user code and Flink
    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender
    rootLogger.appenderRef.rolling.ref = RollingFileAppender
    
    # Uncomment this if you want to _only_ change Flink's logging
    #logger.flink.name = org.apache.flink
    #logger.flink.level = INFO
    
    # The following lines keep the log level of common libraries/connectors on
    # log level INFO. The root logger does not override this. You have to manually
    # change the log levels here.
    logger.akka.name = akka
    logger.akka.level = INFO
    logger.kafka.name= org.apache.kafka
    logger.kafka.level = INFO
    logger.hadoop.name = org.apache.hadoop
    logger.hadoop.level = INFO
    logger.zookeeper.name = org.apache.zookeeper
    logger.zookeeper.level = INFO
    
    # Log all infos to the console
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    
    # Log all infos in the given rolling file
    appender.rolling.name = RollingFileAppender
    appender.rolling.type = RollingFile
    appender.rolling.append = false
    appender.rolling.fileName = ${sys:log.file}
    appender.rolling.filePattern = ${sys:log.file}.%i
    appender.rolling.layout.type = PatternLayout
    appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    appender.rolling.policies.type = Policies
    appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
    appender.rolling.policies.size.size=100MB
    appender.rolling.strategy.type = DefaultRolloverStrategy
    appender.rolling.strategy.max = 10
    
    # Suppress the irrelevant (wrong) warnings from the Netty channel handler
    logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
    logger.netty.level = OFF
    
    # Flink Deployment Logging Overrides
    # rootLogger.level = DEBUG
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/050-ConfigMap-strimzi-cluster-operator.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: strimzi-cluster-operator
  namespace: components
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: logging-config-map
    release: oryx
    heritage: Helm
data:
  log4j2.properties: |
    name = COConfig
    monitorInterval = 30

    appender.console.type = Console
    appender.console.name = STDOUT
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

    rootLogger.level = ${env:STRIMZI_LOG_LEVEL:-INFO}
    rootLogger.appenderRefs = stdout
    rootLogger.appenderRef.console.ref = STDOUT

    # Kafka AdminClient logging is a bit noisy at INFO level
    logger.kafka.name = org.apache.kafka
    logger.kafka.level = WARN

    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default
    logger.zookeepertrustmanager.name = org.apache.zookeeper
    logger.zookeepertrustmanager.level = WARN

    # Keeps separate level for Netty logging -> to not be changed by the root logger
    logger.netty.name = io.netty
    logger.netty.level = INFO
---
# Source: oryx-gateway/templates/gateway-configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: oryx-gateway
  labels:
    app: oryx-gateway
    release: oryx
    chart: oryx-gateway-3.0.0
    oda.tmforum.org/componentName: oryx-eventmanagement
data:
  SCHEMA_REGISTRY_VENDOR: apicurio
  SCHEMA_REGISTRY_URL: http://oryx-apicurio-registry:8080/apis/registry/v2/
  VALUE_DECORATOR: none
  TOPIC_NAMING_STRATEGY: suffixed_name
  TOPICS_TOPIC: TMF688.topic.notification
  HUBS_TOPIC: TMF688.hub.notification
  FLINK_URL: http://oryx-flink-rest:8081
---
# Source: oryx-gateway/templates/gateway-configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: oryx-gateway-files
  labels:
    app: oryx-gateway
    release: oryx
    chart: oryx-gateway-3.0.0
    oda.tmforum.org/componentName: oryx-eventmanagement
data:
  "broker.properties": |
    bootstrap.servers=http://oryx-kafka-kafka-bootstrap:9092
---
# Source: oryx-gateway/templates/dependency-flink.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: oryx-flink-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 40Gi
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: flink-operator
  namespace: components
  labels:
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: "1.8.0"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: flink-kubernetes-operator-1.8.0
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - services
      - events
      - configmaps
      - secrets
    verbs:
      - "*"
  - apiGroups:
      - apps
    resources:
      - deployments
      - deployments/scale
      - deployments/finalizers
      - replicasets
    verbs:
      - "*"
  - apiGroups:
      - extensions
    resources:
      - deployments
      - ingresses
    verbs:
      - "*"
  - apiGroups:
      - flink.apache.org
    resources:
      - flinkdeployments
      - flinkdeployments/status
      - flinkdeployments/finalizers
      - flinksessionjobs
      - flinksessionjobs/status
      - flinksessionjobs/finalizers
    verbs:
      - "*"
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - "*"
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - "*"
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/020-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-namespaced
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: role
    release: oryx
    heritage: Helm
rules:
# Resources in this role are used by the operator based on an operand being deployed in some namespace. When needed, you
# can deploy the operator as a cluster-wide operator. But grant the rights listed in this role only on the namespaces
# where the operands will be deployed. That way, you can limit the access the operator has to other namespaces where it
# does not manage any clusters.
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to access and manage rolebindings to grant Strimzi components cluster permissions
  - rolebindings
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to access and manage roles to grant the entity operator permissions
  - roles
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
    # The cluster operator needs to access and delete pods, this is to allow it to monitor pod health and coordinate rolling updates
  - pods
    # The cluster operator needs to access and manage service accounts to grant Strimzi components cluster permissions
  - serviceaccounts
    # The cluster operator needs to access and manage config maps for Strimzi components configuration
  - configmaps
    # The cluster operator needs to access and manage services and endpoints to expose Strimzi components to network traffic
  - services
  - endpoints
    # The cluster operator needs to access and manage secrets to handle credentials
  - secrets
    # The cluster operator needs to access and manage persistent volume claims to bind them to Strimzi components for persistent data
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "apps"
  resources:
    # The cluster operator needs to access and manage deployments to run deployment based Strimzi components
  - deployments
    # The cluster operator needs to access and manage stateful sets to run stateful sets based Strimzi components
  - statefulsets
    # The cluster operator needs to access replica-sets to manage Strimzi components and to determine error states
  - replicasets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "apps"
  resources:
    # The Cluster Operator needs to scale Deployments while migrating Connect and Mirror Maker 2 clusters from Deployments to StrimziPodSets
  - deployments/scale
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - ""   # legacy core events api, used by topic operator
  - "events.k8s.io" # new events api, used by cluster operator
  resources:
    # The cluster operator needs to be able to create events and delegate permissions to do so
  - events
  verbs:
  - create
- apiGroups:
    # Kafka Connect Build on OpenShift requirement
  - build.openshift.io
  resources:
  - buildconfigs
  - buildconfigs/instantiate
  - builds
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - networking.k8s.io
  resources:
    # The cluster operator needs to access and manage network policies to lock down communication between Strimzi components
  - networkpolicies
    # The cluster operator needs to access and manage ingresses which allow external access to the services in a cluster
  - ingresses
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - route.openshift.io
  resources:
    # The cluster operator needs to access and manage routes to expose Strimzi components for external access
  - routes
  - routes/custom-host
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - image.openshift.io
  resources:
  # The cluster operator needs to verify the image stream when used for Kafka Connect image build
  - imagestreams
  verbs:
  - get
- apiGroups:
  - policy
  resources:
    # The cluster operator needs to access and manage pod disruption budgets this limits the number of concurrent disruptions
    # that a Strimzi component experiences, allowing for higher availability
  - poddisruptionbudgets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/021-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-global
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: role
    release: oryx
    heritage: Helm
rules:
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to create and manage cluster role bindings in the case of an install where a user
    # has specified they want their cluster role bindings generated
  - clusterrolebindings
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
    # The cluster operator requires "get" permissions to view storage class details
    # This is because only a persistent volume of a supported storage class type can be resized
  - storageclasses
  verbs:
  - get
- apiGroups:
    - ""
  resources:
    # The cluster operator requires "list" permissions to view all nodes in a cluster
    # The listing is used to determine the node addresses when NodePort access is configured
    # These addresses are then exposed in the custom resource states
  - nodes
  verbs:
  - list
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/022-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-leader-election
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: role
    release: oryx
    heritage: Helm
rules:
- apiGroups:
  - coordination.k8s.io
  resources:
    # The cluster operator needs to access and manage leases for leader election
    # The "create" verb cannot be used with "resourceNames"
  - leases
  verbs:
  - create
- apiGroups:
  - coordination.k8s.io
  resources:
    # The cluster operator needs to access and manage leases for leader election
  - leases
  resourceNames:
    # The default RBAC files give the operator only access to the Lease resource names strimzi-cluster-operator
    # If you want to use another resource name or resource namespace, you have to configure the RBAC resources accordingly
  - strimzi-cluster-operator
  verbs:
  - get
  - list
  - watch
  - delete
  - patch
  - update
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/023-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-watched
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: role
    release: oryx
    heritage: Helm
rules:
# Resources in this role are being watched by the operator. When operator is deployed as cluster-wide, these permissions
# need to be granted to the operator on a cluster wide level as well, even if the operands will be deployed only in
# few of the namespaces in given cluster. This is required to set up the Kubernetes watches and informers.
# Note: The rights included in this role might change in the future
- apiGroups:
  - ""
  resources:
    # The cluster operator needs to access and delete pods, this is to allow it to monitor pod health and coordinate rolling updates
  - pods
  verbs:
  - watch
  - list
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  # The Cluster Operator operates the Strimzi custom resources
  - kafkas
  - kafkanodepools
  - kafkaconnects
  - kafkaconnectors
  - kafkamirrormakers
  - kafkabridges
  - kafkamirrormaker2s
  - kafkarebalances
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  # The Cluster Operator needs to manage the status of the Strimzi custom resources
  - kafkas/status
  - kafkanodepools/status
  - kafkaconnects/status
  - kafkaconnectors/status
  - kafkamirrormakers/status
  - kafkabridges/status
  - kafkamirrormaker2s/status
  - kafkarebalances/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - "core.strimzi.io"
  resources:
  # The cluster operator uses StrimziPodSets to manage the Kafka and ZooKeeper pods
  - strimzipodsets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "core.strimzi.io"
  resources:
  # The Cluster Operator needs to manage the status of the StrimziPodSet custom resource
  - strimzipodsets/status
  verbs:
  - get
  - patch
  - update
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/030-ClusterRole-strimzi-kafka-broker.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-kafka-broker
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: broker-role
    release: oryx
    heritage: Helm
rules:
- apiGroups:
  - ""
  resources:
    # The Kafka Brokers require "get" permissions to view the node they are on
    # This information is used to generate a Rack ID that is used for High Availability configurations
  - nodes
  verbs:
  - get
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/031-ClusterRole-strimzi-entity-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-entity-operator
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: entity-operator-role
    release: oryx
    heritage: Helm
rules:
- apiGroups:
  - "kafka.strimzi.io"
  resources:
    # The Entity Operator contains the Topic Operator which needs to access and manage KafkaTopic resources
  - kafkatopics
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - "kafka.strimzi.io"
  resources:
    # The Entity Operator contains the User Operator which needs to access and manage KafkaUser resources
  - kafkausers
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
- apiGroups:
  - "kafka.strimzi.io"
  resources:
    # The Entity Operator contains the Topic Operator which needs to access and manage KafkaTopic resources
  - kafkatopics/status
    # The Entity Operator contains the User Operator which needs to access and manage KafkaUser resources
  - kafkausers/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
    # The entity operator needs to be able to create events
  - create
- apiGroups:
  - ""
  resources:
    # The entity operator user-operator needs to access and manage secrets to store generated credentials
  - secrets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/033-ClusterRole-strimzi-kafka-client.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-kafka-client
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: client-role
    release: oryx
    heritage: Helm
rules:
- apiGroups:
  - ""
  resources:
    # The Kafka clients (Connect, Mirror Maker, etc.) require "get" permissions to view the node they are on
    # This information is used to generate a Rack ID (client.rack option) that is used for consuming from the closest
    # replicas when enabled
  - nodes
  verbs:
  - get
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: flink-operator-role-binding
  namespace: components
  labels:
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: "1.8.0"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: flink-kubernetes-operator-1.8.0
roleRef:
  kind: ClusterRole
  name: flink-operator
  apiGroup: rbac.authorization.k8s.io
subjects:
  - kind: ServiceAccount
    name: flink-operator
    namespace: components
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/021-ClusterRoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: role-binding
    release: oryx
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: components
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-global
  apiGroup: rbac.authorization.k8s.io
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-broker-delegation
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: broker-role-binding
    release: oryx
    heritage: Helm
# The Kafka broker cluster role must be bound to the cluster operator service account so that it can delegate the cluster role to the Kafka brokers.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: components
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-broker
  apiGroup: rbac.authorization.k8s.io
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-client-delegation
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: client-role-binding
    release: oryx
    heritage: Helm
# The Kafka clients cluster role must be bound to the cluster operator service account so that it can delegate the
# cluster role to the Kafka clients using it for consuming from closest replica.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: components
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-client
  apiGroup: rbac.authorization.k8s.io
---
# Source: oryx-gateway/charts/apicurio-registry/templates/rbac-sync.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: oryx-apicurio-registry
rules:
  - apiGroups:
      - apiextensions.k8s.io
    resources:
      # the Java operator SDK seems to need listing CRDs
      - customresourcedefinitions
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - artifact.apicur.io
    resources:
      # operator main custom resources
      - artifacts
      - artifacts/status
    verbs:
      - get
      - list
      - watch
      - create
      - delete
      - patch
      - update
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: flink
  namespace: components
  labels:
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: "1.8.0"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: flink-kubernetes-operator-1.8.0
  annotations:
    "helm.sh/resource-policy": keep
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - configmaps
    verbs:
      - '*'
  - apiGroups:
      - apps
    resources:
      - deployments
      - deployments/finalizers
    verbs:
      - '*'
---
# Source: oryx-gateway/charts/apicurio-registry/templates/rbac-sync.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: oryx-apicurio-registry
subjects:
  - kind: ServiceAccount
    name: oryx-apicurio-registry
roleRef:
  kind: Role
  name: oryx-apicurio-registry
  apiGroup: rbac.authorization.k8s.io
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: flink-role-binding
  namespace: components
  labels:
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: "1.8.0"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: flink-kubernetes-operator-1.8.0
  annotations:
    "helm.sh/resource-policy": keep
roleRef:
  kind: Role
  name: flink
  apiGroup: rbac.authorization.k8s.io
subjects:
  - kind: ServiceAccount
    name: flink
    namespace: components
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/020-RoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator
  namespace: components
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: role-binding
    release: oryx
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: components
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-namespaced
  apiGroup: rbac.authorization.k8s.io
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/022-RoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-leader-election
  namespace: components
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: role-binding
    release: oryx
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: components
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-leader-election
  apiGroup: rbac.authorization.k8s.io
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/023-RoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-watched
  namespace: components
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: role-binding
    release: oryx
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: components
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-watched
  apiGroup: rbac.authorization.k8s.io
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-entity-operator-delegation
  namespace: components
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: entity-operator-role-binding
    release: oryx
    heritage: Helm
# The Entity Operator cluster role must be bound to the cluster operator service account so that it can delegate the cluster role to the Entity Operator.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: components
roleRef:
  kind: ClusterRole
  name: strimzi-entity-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: oryx-gateway/charts/apicurio-registry/templates/service-registry.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    helm.sh/chart: "apicurio-registry-3.8.0"
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: oryx
  name: oryx-apicurio-registry
spec:
  selector:
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: oryx
    app.kubernetes.io/component: registry
  ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/webhook.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: flink-operator-webhook-service
  namespace: components
spec:
  ports:
  - port: 443
    targetPort: 9443
  selector:
    app.kubernetes.io/name: flink-kubernetes-operator
---
# Source: oryx-gateway/templates/gateway-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: oryx-gateway
  labels:
    app: oryx-gateway
    release: oryx
    chart: oryx-gateway-3.0.0
    oda.tmforum.org/componentName: oryx-eventmanagement
spec:
  type: ClusterIP
  ports:
    - name: oryx-gateway
      protocol: TCP
      port: 8080
      targetPort: 8080
  selector:
    app: oryx-gateway
    release: oryx
---
# Source: oryx-gateway/charts/apicurio-registry/templates/deployment-registry.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oryx-apicurio-registry
  labels:
    helm.sh/chart: "apicurio-registry-3.8.0"
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: oryx
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: apicurio-registry
      app.kubernetes.io/instance: oryx
      app.kubernetes.io/component: registry
  template:
    metadata:
      labels:
        app.kubernetes.io/name: apicurio-registry
        app.kubernetes.io/instance: oryx
        app.kubernetes.io/component: registry
    spec:
      serviceAccountName: oryx-apicurio-registry
      containers:
        - name: registry
          image: quay.io/apicurio/apicurio-registry-kafkasql:2.5.8.Final
          ports:
            - containerPort: 8080
              name: http
              protocol: TCP
          env:
            - name: REGISTRY_LOG_LEVEL
              value: INFO
            - name: LOG_LEVEL
              value: INFO
            - name: QUARKUS_PROFILE
              value: prod
            - name: KAFKA_BOOTSTRAP_SERVERS
              value: oryx-kafka-kafka-bootstrap:9092
          livenessProbe:
            httpGet:
              path: /health/live
              port: 8080
            periodSeconds: 30
            initialDelaySeconds: 15
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health/ready
              port: 8080
            periodSeconds: 20
            initialDelaySeconds: 15
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          resources:
            
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 256Mi
---
# Source: oryx-gateway/charts/apicurio-registry/templates/deployment-sync.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oryx-apicurio-registry-sync
  labels:
    helm.sh/chart: "apicurio-registry-3.8.0"
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: oryx
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: apicurio-registry
      app.kubernetes.io/instance: oryx
      app.kubernetes.io/component: sync
  template:
    metadata:
      labels:
        app.kubernetes.io/name: apicurio-registry
        app.kubernetes.io/instance: oryx
        app.kubernetes.io/component: sync
    spec:
      serviceAccountName: oryx-apicurio-registry
      containers:
        - name: sync
          image: quay.io/apicurio/apicurio-registry-kube-sync:1.0.1
          imagePullPolicy: "Always"
          env:
            - name: APICURIO_REGISTRY_URL
              value: http://oryx-apicurio-registry:8080/apis/registry/v2
            - name: QUARKUS_LOG_LEVEL
              value: INFO
            - name: LOG_LEVEL
              value: DEBUG
            - name: WATCH_NAMESPACES
              value: components
          ports:
            - containerPort: 8787
              name: http
              protocol: TCP
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /q/health/live
              port: 8787
              scheme: HTTP
            initialDelaySeconds: 0
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /q/health/ready
              port: 8787
              scheme: HTTP
            initialDelaySeconds: 0
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/flink-operator.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flink-kubernetes-operator
  namespace: components
  labels:
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: "1.8.0"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: flink-kubernetes-operator-1.8.0
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: flink-kubernetes-operator
  template:
    metadata:
      labels:
        app.kubernetes.io/name: flink-kubernetes-operator
      annotations:
        kubectl.kubernetes.io/default-container: flink-kubernetes-operator
    spec:
      securityContext:
        runAsGroup: 9999
        runAsUser: 9999
      serviceAccountName: flink-operator
      containers:
        - name: flink-kubernetes-operator
          image: ghcr.io/apache/flink-kubernetes-operator:91d67d9
          imagePullPolicy: IfNotPresent
          command: ["/docker-entrypoint.sh", "operator"]
          ports:
            - containerPort: 8085
              name: health-port
              protocol: TCP
          env:
            - name: OPERATOR_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OPERATOR_NAME
              value: flink-kubernetes-operator
            - name: FLINK_CONF_DIR
              value: /opt/flink/conf
            - name: FLINK_PLUGINS_DIR
              value: /opt/flink/plugins
            - name: LOG_CONFIG
              value: -Dlog4j.configurationFile=/opt/flink/conf/log4j-operator.properties
            - name: JVM_ARGS
              value: 
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
            - name: flink-operator-config-volume
              mountPath: /opt/flink/conf
            - name: flink-artifacts-volume
              mountPath: /opt/flink/artifacts
          livenessProbe:
            initialDelaySeconds: 30
            periodSeconds: 10
            httpGet:
              path: /
              port: health-port
          startupProbe:
            failureThreshold: 30
            periodSeconds: 10
            httpGet:
              path: /
              port: health-port
        - name: flink-webhook
          image: ghcr.io/apache/flink-kubernetes-operator:91d67d9
          imagePullPolicy: IfNotPresent
          command: ["/docker-entrypoint.sh", "webhook"]
          env:
            - name: WEBHOOK_KEYSTORE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: flink-operator-webhook-secret
                  key: password
            - name: WEBHOOK_KEYSTORE_FILE
              value: "/certs/keystore.p12"
            - name: WEBHOOK_KEYSTORE_TYPE
              value: "pkcs12"
            - name: WEBHOOK_SERVER_PORT
              value: "9443"
            - name: LOG_CONFIG
              value: -Dlog4j.configurationFile=/opt/flink/conf/log4j-operator.properties
            - name: JVM_ARGS
              value: 
            - name: FLINK_CONF_DIR
              value: /opt/flink/conf
            - name: FLINK_PLUGINS_DIR
              value: /opt/flink/plugins
            - name: OPERATOR_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
          - name: keystore
            mountPath: "/certs"
            readOnly: true
          - name: flink-operator-config-volume
            mountPath: /opt/flink/conf
      volumes:
        - name: flink-operator-config-volume
          configMap:
            name: flink-operator-config
            items:
              - key: flink-conf.yaml
                path: flink-conf.yaml
              - key: log4j-operator.properties
                path: log4j-operator.properties
              - key: log4j-console.properties
                path: log4j-console.properties
        - name: flink-artifacts-volume
          emptyDir: {}
        - name: keystore
          secret:
            secretName: webhook-server-cert
            items:
            - key: keystore.p12
              path: keystore.p12
---
# Source: oryx-gateway/charts/strimzi-kafka-operator/templates/060-Deployment-strimzi-cluster-operator.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: strimzi-cluster-operator
  namespace: components
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.40.0
    component: deployment
    release: oryx
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      name: strimzi-cluster-operator
      strimzi.io/kind: cluster-operator
  template:
    metadata:
      labels:
        name: strimzi-cluster-operator
        strimzi.io/kind: cluster-operator
    spec:
      serviceAccountName: strimzi-cluster-operator
      volumes:
        - name: strimzi-tmp
          emptyDir:
            medium: Memory
            sizeLimit: 1Mi
        - name: co-config-volume
          configMap:
            name: strimzi-cluster-operator
      containers:
        - name: strimzi-cluster-operator
          image: quay.io/strimzi/operator:0.40.0
          ports:
            - containerPort: 8080
              name: http
          args:
            - /opt/strimzi/bin/cluster_operator_run.sh
          volumeMounts:
            - name: strimzi-tmp
              mountPath: /tmp
            - name: co-config-volume
              mountPath: /opt/strimzi/custom-config/
          env:
            - name: STRIMZI_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS
              value: "120000"
            - name: STRIMZI_OPERATION_TIMEOUT_MS
              value: "300000"
            - name: STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE
              value: quay.io/strimzi/kafka:0.40.0-kafka-3.7.0
            - name: STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE
              value: quay.io/strimzi/kafka:0.40.0-kafka-3.7.0
            - name: STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE
              value: quay.io/strimzi/kafka:0.40.0-kafka-3.7.0
            - name: STRIMZI_KAFKA_IMAGES
              value: |                 
                3.6.0=quay.io/strimzi/kafka:0.40.0-kafka-3.6.0
                3.6.1=quay.io/strimzi/kafka:0.40.0-kafka-3.6.1
                3.7.0=quay.io/strimzi/kafka:0.40.0-kafka-3.7.0
            - name: STRIMZI_KAFKA_CONNECT_IMAGES
              value: |                 
                3.6.0=quay.io/strimzi/kafka:0.40.0-kafka-3.6.0
                3.6.1=quay.io/strimzi/kafka:0.40.0-kafka-3.6.1
                3.7.0=quay.io/strimzi/kafka:0.40.0-kafka-3.7.0
            - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES
              value: |                 
                3.6.0=quay.io/strimzi/kafka:0.40.0-kafka-3.6.0
                3.6.1=quay.io/strimzi/kafka:0.40.0-kafka-3.6.1
                3.7.0=quay.io/strimzi/kafka:0.40.0-kafka-3.7.0
            - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES
              value: |                 
                3.6.0=quay.io/strimzi/kafka:0.40.0-kafka-3.6.0
                3.6.1=quay.io/strimzi/kafka:0.40.0-kafka-3.6.1
                3.7.0=quay.io/strimzi/kafka:0.40.0-kafka-3.7.0
            - name: STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE
              value: quay.io/strimzi/operator:0.40.0
            - name: STRIMZI_DEFAULT_USER_OPERATOR_IMAGE
              value: quay.io/strimzi/operator:0.40.0
            - name: STRIMZI_DEFAULT_KAFKA_INIT_IMAGE
              value: quay.io/strimzi/operator:0.40.0
            - name: STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE
              value: quay.io/strimzi/kafka-bridge:0.28.0
            - name: STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE
              value: quay.io/strimzi/kaniko-executor:0.40.0
            - name: STRIMZI_DEFAULT_MAVEN_BUILDER
              value: quay.io/strimzi/maven-builder:0.40.0
            - name: STRIMZI_OPERATOR_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            
            - name: STRIMZI_FEATURE_GATES
              value: ""
            - name: STRIMZI_LEADER_ELECTION_ENABLED
              value: "true"
            - name: STRIMZI_LEADER_ELECTION_LEASE_NAME
              value: "strimzi-cluster-operator"
            - name: STRIMZI_LEADER_ELECTION_LEASE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: STRIMZI_LEADER_ELECTION_IDENTITY
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          livenessProbe:
            httpGet:
              path: /healthy
              port: http
            initialDelaySeconds: 10
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 10
            periodSeconds: 30
          resources:
            limits:
              cpu: 1000m
              memory: 384Mi
            requests:
              cpu: 200m
              memory: 384Mi
---
# Source: oryx-gateway/templates/gateway-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oryx-gateway
  labels:
    app: oryx-gateway
    release: oryx
    chart: oryx-gateway-3.0.0
    oda.tmforum.org/componentName: oryx-eventmanagement
spec:
  selector:
    matchLabels:
      app: oryx-gateway
      release: oryx
  replicas: 1
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: oryx-gateway
        release: oryx
        chart: oryx-gateway-3.0.0
        oda.tmforum.org/componentName: oryx-eventmanagement
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: "app"
                      operator: In
                      values:
                        - oryx-gateway
                topologyKey: "kubernetes.io/hostname"
      imagePullSecrets:
        - name: "gateway-registry"
      containers:
        - name: oryx-gateway
          image: oryxgateway/gateway:3.1.0-devel
          imagePullPolicy: "Always"
          ports:
            - containerPort: 8080
              name: http
          resources:
            limits:
              cpu: 1000m
              memory: 2Gi
            requests:
              cpu: 500m
              memory: 1Gi
          envFrom:
            - configMapRef:
                name: oryx-gateway
          env:
            - name: RELEASE_NAME
              value: oryx
            - name: COMPONENT_NAME
              value: oryx-eventmanagement
          startupProbe:
            failureThreshold: 15
            periodSeconds: 10
            httpGet:
              path: /oryx-eventmanagement/tmf-api/actuator/health
              port: 8080
          livenessProbe:
            initialDelaySeconds: 5
            periodSeconds: 30
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
            httpGet:
              path: /oryx-eventmanagement/tmf-api/actuator/health
              port: 8080
          volumeMounts:
            - mountPath: /opt/oryxgateway/config
              name: configs
      volumes:
        - name: configs
          configMap:
            name: oryx-gateway-files
---
# Source: oryx-gateway/templates/gateway-init-job.yaml
apiVersion: batch/v1  
kind: Job  
metadata:  
  name: oryx-gateway-d34ba570-372e-4c11-beee-862d92ba14f5
  labels:
    app: oryx-gateway
    release: oryx
    chart: oryx-gateway-3.0.0
    oda.tmforum.org/componentName: oryx-eventmanagement
spec:  
  template:  
    metadata:
      labels:
        app: oryx-gateway
        release: oryx
        chart: oryx-gateway-3.0.0
        oda.tmforum.org/componentName: oryx-eventmanagement
        sidecar.istio.io/inject: "false"
    spec:
      restartPolicy: OnFailure
      imagePullSecrets:
        - name: "gateway-registry"
      containers:
        - name: oryx-gateway-init
          image: oryxgateway/gateway-init:3.1.0-devel 
          imagePullPolicy: "Always"
          resources:
            limits:
              cpu: 1000m
              memory: 4Gi
            requests:
              cpu: 500m
              memory: 2Gi
          envFrom:
            - configMapRef:
                name: oryx-gateway
          volumeMounts:
            - mountPath: /opt/oryxgateway/config
              name: configs
      volumes:
        - name: configs
          configMap:
            name: oryx-gateway-files
---
# Source: oryx-gateway/templates/dependency-broker-kafkaui.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: oryx-kafka-ui
  labels:
    app: oryx-gateway
    release: oryx
    chart: oryx-gateway-3.0.0
spec:
  rules:
    - host: kafka.oryx.itrative.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: oryx-kafka-ui
                port:
                  number: 80
---
# Source: oryx-gateway/templates/dependency-flink.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: oryx-flink
  labels:
    release: oryx
    chart: oryx-gateway-3.0.0
    oda.tmforum.org/componentName: oryx-eventmanagement
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 500m
spec:
  rules:
    - host: flink.oryx.itrative.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: oryx-flink-rest
                port:
                  number: 8081
---
# Source: oryx-gateway/templates/gateway-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: oryx-gateway
  labels:
    app: oryx-gateway
    release: oryx
    chart: oryx-gateway-3.0.0
    oda.tmforum.org/componentName: oryx-eventmanagement
spec:
  rules:
    - host: oryx.itrative.com
      http:
        paths:
          - path: /oryx-eventmanagement/
            pathType: Prefix
            backend:
              service:
                name: oryx-gateway
                port:
                  number: 8080
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/flink-operator.yaml
################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/rbac.yaml
################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/rbac.yaml
---
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/serviceaccount.yaml
################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/webhook.yaml
################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/webhook.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: flink-operator-serving-cert
  namespace: components
spec:
  dnsNames:
  - flink-operator-webhook-service.components.svc
  - flink-operator-webhook-service.components.svc.cluster.local
  keystores:
    pkcs12:
      create: true
      passwordSecretRef:
        name: flink-operator-webhook-secret
        key: password
  issuerRef:
    kind: Issuer
    name: flink-operator-selfsigned-issuer
  commonName: FlinkDeployment Validator
  secretName: webhook-server-cert
---
# Source: oryx-gateway/templates/dependency-flink.yaml
apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  name: oryx-flink
spec:
  image: flink:1.18-java17
  flinkVersion: v1_18
  flinkConfiguration:
    taskmanager.numberOfTaskSlots: "4"
    state.savepoints.dir: file:///flink-data/savepoints
    state.checkpoints.dir: file:///flink-data/checkpoints
    high-availability.type: kubernetes
    high-availability.storageDir: file:///flink-data/restore
    restart-strategy.type: fixed-delay
    restart-strategy.fixed-delay.attempts: "1048576"
    restart-strategy.fixed-delay.delay: "15s"
    rest.client.max-content-length: "524288000"
    rest.server.max-content-length: "524288000"
    env.java.opts.all: "--add-opens=java.base/java.util=ALL-UNNAMED
      --add-opens=java.base/java.lang=ALL-UNNAMED
      --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
      --add-opens=java.base/java.io=ALL-UNNAMED"
  serviceAccount: flink
  mode: native
  podTemplate:
    apiVersion: v1
    kind: Pod 
    metadata:
      name: pod-template
    spec:
      containers:
        - name: flink-main-container
          volumeMounts:
            - name: flink-data
              mountPath: /flink-data
      volumes:
        - name: flink-data
          persistentVolumeClaim:
            claimName: oryx-flink-pvc
  jobManager:
    replicas: 1
    resource:
      memory: 1g
      cpu: 1
  taskManager:
    replicas: 3
    resource:
      memory: 2g
      cpu: 1
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/webhook.yaml
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: flink-operator-selfsigned-issuer
  namespace: components
spec:
  selfSigned: {}
---
# Source: oryx-gateway/templates/dependency-broker-strimzi.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: oryx-kafka
spec:
  kafka:
    version: 3.7.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      inter.broker.protocol.version: "3.7"
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: 10Gi
        deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 10Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/webhook.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: components/flink-operator-serving-cert
  name: flink-operator-components-webhook-configuration
webhooks:
  - name: mutationwebhook.flink.apache.org
    admissionReviewVersions: ["v1"]
    clientConfig:
      service:
        name: flink-operator-webhook-service
        namespace: components
        path: /mutate
    failurePolicy: Fail
    rules:
      - apiGroups: ["flink.apache.org"]
        apiVersions: ["*"]
        scope: "Namespaced"
        operations:
          - CREATE
        resources:
          - flinksessionjobs
    sideEffects: None
---
# Source: oryx-gateway/charts/flink-kubernetes-operator/templates/webhook.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: components/flink-operator-serving-cert
  name: flink-operator-components-webhook-configuration
webhooks:
- name: validationwebhook.flink.apache.org
  admissionReviewVersions: ["v1"]
  clientConfig:
    service:
      name: flink-operator-webhook-service
      namespace: components
      path: /validate
  failurePolicy: Fail
  rules:
  - apiGroups: ["flink.apache.org"]
    apiVersions: ["*"]
    scope: "Namespaced"
    operations:
    - CREATE
    - UPDATE
    resources:
    - flinkdeployments
    - flinksessionjobs
  sideEffects: None
